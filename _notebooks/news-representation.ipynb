{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next:\n",
    "t-sne embed and tensorboard visualization\n",
    "https://github.com/joeddav/blog/blob/master/_notebooks/2020-05-29-ZSL.ipynb\n",
    "https://towardsdatascience.com/bert-text-classification-using-pytorch-723dfb8b6b5b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/sh: /lus/scratch/mzaman/anaconda3/lib/libreadline.so.7: no version information available (required by /usr/bin/sh)\n",
      "/bin/sh: /lus/scratch/mzaman/anaconda3/lib/libreadline.so.7: no version information available (required by /bin/sh)\n",
      "Collecting transformers\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/91ed8f5c4e7ef3227b4119200fc0ed4b4fd965b1f0172021c25701087825/transformers-3.0.2-py3-none-any.whl (769kB)\n",
      "\u001b[K     |████████████████████████████████| 778kB 1.8MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests in /lus/dal/mzaman/anaconda3/envs/torchclone/lib/python3.6/site-packages (from transformers) (2.22.0)\n",
      "Collecting tqdm>=4.27\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/28/7e/281edb5bc3274dfb894d90f4dbacfceaca381c2435ec6187a2c6f329aed7/tqdm-4.48.2-py2.py3-none-any.whl (68kB)\n",
      "\u001b[K     |████████████████████████████████| 71kB 5.2MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /lus/dal/mzaman/anaconda3/envs/torchclone/lib/python3.6/site-packages (from transformers) (1.17.2)\n",
      "Collecting sentencepiece!=0.1.92\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1MB 8.2MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting packaging\n",
      "  Using cached https://files.pythonhosted.org/packages/46/19/c5ab91b1b05cfe63cccd5cfc971db9214c6dd6ced54e33c30d5af1d2bc43/packaging-20.4-py2.py3-none-any.whl\n",
      "Collecting tokenizers==0.8.1.rc1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/d0/30d5f8d221a0ed981a186c8eb986ce1c94e3a6e87f994eae9f4aa5250217/tokenizers-0.8.1rc1-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
      "\u001b[K     |████████████████████████████████| 3.0MB 12.9MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting dataclasses; python_version < \"3.7\"\n",
      "  Downloading https://files.pythonhosted.org/packages/e1/d2/6f02df2616fd4016075f60157c7a0452b38d8f7938ae94343911e0fb0b09/dataclasses-0.7-py3-none-any.whl\n",
      "Collecting regex!=2019.12.17\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/66/f2/b3af9ce9df4b7e121dfeece41fc95e37b14f0153821f35d08edb0b0813ff/regex-2020.7.14-cp36-cp36m-manylinux2010_x86_64.whl (660kB)\n",
      "\u001b[K     |████████████████████████████████| 665kB 26.2MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: filelock in /lus/dal/mzaman/anaconda3/envs/torchclone/lib/python3.6/site-packages (from transformers) (3.0.12)\n",
      "Collecting sacremoses\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
      "\u001b[K     |████████████████████████████████| 890kB 26.6MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /lus/dal/mzaman/anaconda3/envs/torchclone/lib/python3.6/site-packages (from requests->transformers) (1.25.6)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /lus/dal/mzaman/anaconda3/envs/torchclone/lib/python3.6/site-packages (from requests->transformers) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /lus/dal/mzaman/anaconda3/envs/torchclone/lib/python3.6/site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /lus/dal/mzaman/anaconda3/envs/torchclone/lib/python3.6/site-packages (from requests->transformers) (2020.4.5.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /lus/dal/mzaman/anaconda3/envs/torchclone/lib/python3.6/site-packages (from packaging->transformers) (2.4.2)\n",
      "Requirement already satisfied: six in /lus/dal/mzaman/anaconda3/envs/torchclone/lib/python3.6/site-packages (from packaging->transformers) (1.12.0)\n",
      "Requirement already satisfied: click in /lus/dal/mzaman/anaconda3/envs/torchclone/lib/python3.6/site-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in /lus/dal/mzaman/anaconda3/envs/torchclone/lib/python3.6/site-packages (from sacremoses->transformers) (0.13.2)\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=d8981a47baddc6fbb3dc16514c5cd6736532a2779af11f08f624a8d16d2affe1\n",
      "  Stored in directory: /home/users/mzaman/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
      "Successfully built sacremoses\n",
      "Installing collected packages: tqdm, sentencepiece, packaging, tokenizers, dataclasses, regex, sacremoses, transformers\n",
      "Successfully installed dataclasses-0.7 packaging-20.4 regex-2020.7.14 sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc1 tqdm-4.48.2 transformers-3.0.2\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[sentence] + labels\n",
    "inputs\n",
    "output[:1].shape\n",
    "sentence_rep.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lus/scratch/mzaman/anaconda3/envs/torchclone/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/lus/scratch/mzaman/anaconda3/envs/torchclone/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/lus/scratch/mzaman/anaconda3/envs/torchclone/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/lus/scratch/mzaman/anaconda3/envs/torchclone/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/lus/scratch/mzaman/anaconda3/envs/torchclone/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/lus/scratch/mzaman/anaconda3/envs/torchclone/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/lus/scratch/mzaman/anaconda3/envs/torchclone/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/lus/scratch/mzaman/anaconda3/envs/torchclone/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/lus/scratch/mzaman/anaconda3/envs/torchclone/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/lus/scratch/mzaman/anaconda3/envs/torchclone/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/lus/scratch/mzaman/anaconda3/envs/torchclone/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/lus/scratch/mzaman/anaconda3/envs/torchclone/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff68ab3729db4465aaa2d1fa46944d54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=385.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2958b834dcaa4ef58ef3aed6dcbe55ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea1972e0e9b14e7eb8066e167f31ca2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=2.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ddc68c458474b31a4e2fa35a5908551",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=112.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fc4fedcdafb4a909c466732beb71705",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=438006864.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "label: politics \t similarity: 0.21561527252197266\n",
      "label: business \t similarity: 0.004524129908531904\n",
      "label: art & culture \t similarity: -0.02739684097468853\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "from torch.nn import functional as F\n",
    "tokenizer = AutoTokenizer.from_pretrained('deepset/sentence_bert')\n",
    "model = AutoModel.from_pretrained('deepset/sentence_bert')\n",
    "\n",
    "sentence = 'Who are you voting for in 2020?'\n",
    "labels = ['business', 'art & culture', 'politics']\n",
    "\n",
    "# run inputs through model and mean-pool over the sequence\n",
    "# dimension to get sequence-level representations\n",
    "inputs = tokenizer.batch_encode_plus([sentence] + labels,\n",
    "                                     return_tensors='pt',\n",
    "                                     pad_to_max_length=True)\n",
    "input_ids = inputs['input_ids']\n",
    "attention_mask = inputs['attention_mask']\n",
    "output = model(input_ids, attention_mask=attention_mask)[0]\n",
    "sentence_rep = output[:1].mean(dim=1)\n",
    "label_reps = output[1:].mean(dim=1)\n",
    "\n",
    "# now find the labels with the highest cosine similarities to\n",
    "# the sentence\n",
    "similarities = F.cosine_similarity(sentence_rep, label_reps)\n",
    "closest = similarities.argsort(descending=True)\n",
    "for ind in closest:\n",
    "    print(f'label: {labels[ind]} \\t similarity: {similarities[ind]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  2040,  2024,  2017,  6830,  2005,  1999, 12609,  1029,   102],\n",
       "        [  101,  2449,   102,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [  101,  2396,  1004,  3226,   102,     0,     0,     0,     0,     0],\n",
       "        [  101,  4331,   102,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 0, 0, 0, 0, 0, 0, 0]])}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
